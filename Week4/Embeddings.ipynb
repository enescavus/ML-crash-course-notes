{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makine öğrenmesinde kategorik verileri numeric hale getirip algoritmalarımızı besleriz. Bunu yapmanın birçok yolu var, mesela one-hot encoding. 1 ve 0'lardan olusan birçok vektör oluşturuyoruz. Bu konuyu kursun bir önceki konularından hatırlıyoruz fakat bazen elimizde ayrık ve çok fazla sayıda kategorik veri olacak. Bu sayı milyonlarca bile olabilir. Bu kadar veriyi \"one-hot encoding\" yöntemi ile dönüştürmek pek mantıklı olmayacaktır. Burada inceleyceğmiz **embedding** ile çok daha iyi modeller eğitebiliriz. Peki nedir bu **embedding**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding ile çok fazla sayıda olan özelliklerimizi, belirlediğmiz boyut sayısınca gruplandırarak sınırlandırıyoruz. Bu şekilde verimizin kontrol altına alınmasına ve modelimizin daha iyi tahminlerde bulunmasına olanak sağlıyoruz.\n",
    "\n",
    "Önce 1D ( bir boyutlu ) örneğimize bakalım. \n",
    "\n",
    "![1D](images/1D.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Görüldüğü üzere elimizde filmlerden oluşan bir veri setimiz var ve bunu bir boyuta yerlestirmeye çalıştık. Tabii ki çok basit ama konuyu anlamak için gayet güzel bir örnek. Burada,filmlerin izleyici kitlesinin yetişkinlik düzeyine göre soldan sağa ayırmaya çalıştığımızı görüyoruz. En solda çoçuklara hitap edenler, en sağda ise yetişkinlere doğru kaymış. Daha net anlamak için bir boyut daha artıralım ve farkı görelim. \n",
    "\n",
    "\n",
    "![2D](images/2D.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Görüldüğü üzere boyut artırdığımızda çok daha mantıklı gruplamalar yapıldı. Film dünyası olarak baktığımızda birçok türden birçok kesime, birçok duyguya hitap eden filmler olduğundan dolayı birkaç boyut ile bu model eğitilemez fakat **embedding**i anlamak için iyi bir örnekti. Şimdi biraz da _nöral ağlar_ kısmına değinelim. Kod aşamasında nasıl bir yol izliyoruz, hangi algoritmayı kullanacağız inceleyelim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İnceleyeceğimiz algoritma Google tarafından geliştirilen **Word2vec** algoritması. Bu algoritma **_anlamsal olarak benzer olan kelimeleri geometrik olarak birbirine yakın vektörler haline getirerek haritalandırıyor_**  Aşağıdaki fotoğrafta bu algoritmanın bir kitap öneri sistemi için yapmış olduğu geometrik gruplandırmayı görüyoruz. Kitap türlerinden benzer olanların birbirlerine yakınlıklarını gözlemleyebilirsiniz.\n",
    "\n",
    "\"We can take the original 37,000 dimensions of all the books on Wikipedia, map them to 50 dimensions using neural network embeddings, and then map them to 2 dimensions using TSNE.\"\n",
    "\n",
    "Yani 37.000 kitabı 50 boyuta indiriyoruz, görselleştirmek amaçlı olarak ise 2D hale getiriliyor. Google'ın öneri sistemlerinde ne kadar başarılı olduğunu görmekteyiz. işte görselin son hali..\n",
    "\n",
    "![word2vec](images/bookEmbedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peki bu algoritma kod kısmında nasıl? Tasarımı nasıl ? kurs üzerinden görseller ile inceleyelim. \n",
    "\n",
    "\n",
    "Aşağıdaki görselde **Embedding** katmanını görüyoruz. 3 adet unit'ten oluşmakta ve bir çok inputu bu unit'lere vermekteyiz. Bu 3 unit ( düğüm ) ile ayrıca eklemeyi istediğimiz başka inputlar da bir diğer katman olan standart, her zaman karşımıza çıkabilecek bir gizli katmana veriliyor. En sonda ise bir onceki konularda değinmiş olduğumuz softmax katmanı var. Burada önemli olan embedding katmanındaki unit sayısı ve boyut belirlememiz.\n",
    "\n",
    "![EmbeddingsNN](images/EmbeddingsNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boyut ve katmandaki unit sayısı arasındaki bağlantıyı anlamak için aşağıdaki resmi inceleyelim.\n",
    "\n",
    "Görüldüğü üzere boyut sayımız **Embedding katmanımızdaki unit sayımız** kadar olmakta. Burada filmleri düşünün ve biz bu filmeleri 3 boyuta sahip olacak şekilde koordinatlara yerleştiriyoruz. 2 boyutlu örneği hatırlarsanız orada (x , y) tarzında iki değer vardı elimizde. Yani orada iki unit'e sahip bir embedding katmanı kullanmış olmalıyız. \n",
    "\n",
    "Aşağıdakine dönersek burada 3 unit var ve biz bu kadar boyut ile filmimizi konumlandırmışız. \n",
    "\n",
    "\n",
    "Çok daha fazlası için ek kaynaklara linkler bırakıyorum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![EmbeddingsWeight](images/EmbeddingsWeight.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ek Kaynaklar\n",
    "\n",
    "- [Google Course Link](https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture)\n",
    "\n",
    "- [Embeddings](https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_EnesÇavuş_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
